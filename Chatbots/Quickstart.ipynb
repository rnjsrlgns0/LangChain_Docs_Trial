{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAGì™€ Memory Chainì„ ëª¨ë‘ ì ìš©í•œ ì±—ë´‡ ë§Œë“¤ê¸°ë¥¼ ìœ„í•œ ì—°ìŠµì…ë‹ˆë‹¤ğŸ™‚\n",
    "# Chabots\n",
    " - llmì— ëŒ€í•œ ê°€ì¥ ì¸ê¸°ìˆëŠ” ì‚¬ìš©ì¼€ì´ìŠ¤\n",
    " - ì˜¤ëœê¸°ê°„ì˜ í•™ìŠµì„ ê±°ì¹˜ë©°, ê´€ë ¨ ì •ë³´ë¥¼ ì´ìš©, í˜„ì¬ìƒí™©ì— ëŒ€í•œ ëŒ€í™”ë¥¼ ë‚˜ëˆŒ ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atchitecture\n",
    " - Chatbotì„ ë””ìì¸í•˜ê¸° ìœ„í•´ì„œëŠ” ì—¬ëŸ¬ ìš”ì†Œë¥¼ ê³ ë ¤í•´ì•¼í•¨\n",
    " - ë‹¹ì—°íˆ DB, Memory ë“± ëª¨ë“  ì •ë³´ë¥¼ ë„£ê³  promptë¥¼ ì œê³µí•˜ë©´ ì„±ëŠ¥ì€ ë†’ì•„ì§€ì§€ë§Œ ì†ë„, ìì› ë“± trade-offë¥¼ ìƒê°í•´ì•¼í•¨\n",
    " - ì•„ë˜ëŠ” ì¼ë°˜ì ì¸ chatbotì˜ ì•„í‚¤í…ì²˜\n",
    " ![Chabot Architecture](./imgs/Chatbot_Architecture.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbotì˜ ê¸°ë³¸ êµ¬ì„±ìš”ì†Œ\n",
    " - Chatmodels : ì‚¬ìš©ì ì¿¼ë¦¬ ë° ì œê³µ ë°ì´í„°ë¥¼ ê°€ì§€ê³  í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  LLMëª¨ë¸\n",
    " - PromptTemplates : ëª¨ë¸ì´ ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ì„ ì˜ ë°›ì•„ë“¤ì´ê²Œ í•˜ê³ , ì¶œë ¥ë¬¼ì˜ ê²°ê³¼ë¥¼ ì‚¬ìš©ìê°€ ì›í•˜ëŠ” í˜•íƒœë¡œ ë§Œë“¤ê¸° ìœ„í•œ template\n",
    " - ChatHistory : ì‚¬ìš©ìì™€ì˜ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥, ë‹¤ìŒ ë‹µë³€ ì‹œ ì´ì „ì˜ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìˆìŒ\n",
    " - Retrievers : ì‚¬ìš©ìì˜ ì¿¼ë¦¬ë¥¼ í†µí•´ ì ì •í•œ ë°ì´í„°ë¥¼ ì°¾ì•„ì„œ Chatmodelsì—ê²Œ ì œê³µí•´ì£¼ëŠ” ì—­í• \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('../dot.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìš°ì„ ì€ GPT ëª¨ë¸ì„ ì‚¬ìš©í•´ë´…ë‹ˆë‹¤\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# chat = ChatOpenAI(\n",
    "#                    base_url=\"http://localhost:1234/v1\",\n",
    "#                    api_key=\"lm-studio\",\n",
    "#                    model=\"teddylee777/EEVE-Korean-Instruct-10.8B-v1.0-gguf\",\n",
    "#                    temperature = 0.0,\n",
    "#                    )\n",
    "chat = ChatOpenAI(\n",
    "                   base_url=\"http://localhost:1234/v1\",\n",
    "                   api_key=\"lm-studio\",\n",
    "                   model=\"cognitivecomputations/dolphin-2.9-llama3-8b-gguf\",\n",
    "                   temperature = 0.0,\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Je adore programmer.', response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 4, 'total_tokens': 8}, 'model_name': 'cognitivecomputations/dolphin-2.9-llama3-8b-gguf', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-aac46aed-ea59-48e7-b302-ebe2e582d853-0')"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import AIMessage as AIM\n",
    "\n",
    "chat.invoke(\n",
    "    [HumanMessage(content = \"Translate this sentence from English to French: I love programming.\")])\n",
    "\n",
    "#ì§ˆì˜ í˜•ì‹ ë³´ê¸°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ìœ„ ìƒíƒœì˜ ì±—ë´‡ì€ ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ì§€ ëª»í•©ë‹ˆë‹¤.\n",
    " - ê°€ì¥ ê°„ë‹¨í•œ ë°©ì‹ìœ¼ë¡œ ì´ì „ì˜ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ê²Œë” chatbotì„ êµ¬ì„±í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human Messageì™€ AIMessageê°€ ì„ì—¬ìˆì„ ë•Œ Chatbotì€ ê°€ì¥ ìµœê·¼ì˜ Human Messageì— ëŒ€í•´ ëŒ€í™”ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I said \"J\\'aime le codage\" which means \"I love programming\" in French.\\n'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIMessage = chat.invoke(\n",
    "    [\n",
    "        HumanMessage(content = \"Translate this sentence from English to French: I love programming.\"),\n",
    "        AIM(content = \"J'aime le codage\"),\n",
    "        HumanMessage(content = \"What did you just say?\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "AIMessage.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PromptTemplateì„ ì£¼ë©´ Chatbotì´ ë”ìš± íš¨ìœ¨ì ìœ¼ë¡œ ê³¼ì œë¥¼ ì•Œì•„ë“¤ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- ìš°ë¦¬ëŠ” modelì— templateì„ ë„£ëŠ” ë°©ì‹ìœ¼ë¡œ ì´ë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# promptëŠ” ëª¨ë¸ì— ì˜ ì…ë ¥ë  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ì •ì˜í•´ì•¼í•©ë‹ˆë‹¤.\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\"\n",
    "        ),\n",
    "        # MessagesPlaceholderëŠ” ëŒ€í™”ì˜ ì´ì „ ë©”ì‹œì§€ë“¤ì„ í¬í•¨í•˜ëŠ” ë³€ìˆ˜ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì±—ë´‡ì€ ì´ì „ ëŒ€í™”ì˜ ë§¥ë½ì„ ì´í•´í•˜ê³ , ì—°ì†ì ì¸ ëŒ€í™”ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 'messages'ë¼ëŠ” ë³€ìˆ˜ ì´ë¦„ìœ¼ë¡œ ì´ì „ ë©”ì‹œì§€ë“¤ì„ ì°¸ì¡°í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
    "        MessagesPlaceholder(variable_name = \"messages\")\n",
    "])\n",
    "chain = prompt | chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Messageë“¤ ìì²´ë¥¼ ë©”íƒ€ë°ì´í„°ë¡œ ì£¼ì–´ ê¸°ì–µí•˜ê²Œ í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
    "- MessagePlaceholderëŠ” ëŒ€í™”ì˜ ì´ì „ ë©”ì‹œì§€ë“¤ì„ í¬í•¨í•˜ëŠ” ë³€ìˆ˜ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì±—ë´‡ì€ ì´ì „ ëŒ€í™”ì˜ ë§¥ë½ì„ ì´í•´í•˜ê³ , ì—°ì†ì ì¸ ëŒ€í™”ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 'messages'ë¼ëŠ” ë³€ìˆ˜ ì´ë¦„ìœ¼ë¡œ ì´ì „ ë©”ì‹œì§€ë“¤ì„ ì°¸ì¡°í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I said, \"J\\'adore la programmation,\" which translates to \"I love programming\" in English.\\n'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"Translate this sentence from English to French: I love programming.\"),\n",
    "            AIM(content=\"J'adore la programmation.\"),\n",
    "            HumanMessage(content=\"What did you just say?\"),\n",
    "        ],\n",
    "    }\n",
    ").content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message history\n",
    "- ì±„íŒ… ê¸°ë¡ì„ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ê°„í¸í•œ ë°©ë²•ìœ¼ë¡œ, ì±„íŒ… ë©”ì‹œì§€ë¥¼ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ëŠ” ì—­í• ì„ í•˜ëŠ” MessageHistory í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "- ë‹¤ì–‘í•œ ë°ì´í„°ë² ì´ìŠ¤ì— ë©”ì‹œì§€ë¥¼ ì§€ì†ì ìœ¼ë¡œ ì €ì¥í•˜ëŠ” ë§ì€ ë‚´ì¥ ë©”ì‹œì§€ ê¸°ë¡ í†µí•© ê¸°ëŠ¥ì´ ìˆì§€ë§Œ, ì´ ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œì—ì„œëŠ” ë©”ëª¨ë¦¬ ë‚´ì—ì„œ ì‘ë™í•˜ëŠ” ë°ëª¨ ë©”ì‹œì§€ ê¸°ë¡ì¸ ChatMessageHistoryë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi'), HumanMessage(content=\"what's up?\")]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ChatMessagehistoryë¥¼ ì´ìš©í•˜ë©´ ê°„ë‹¨í•œ ë°©ì‹ìœ¼ë¡œ Memoryë¥¼ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ ê°€ë ¹,\n",
    "from langchain.memory import ChatMessageHistory\n",
    "#ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "chathistory = ChatMessageHistory()\n",
    "#add_user_message()ë©”ì„œë“œë¥¼ ì´ìš©í•œ ìœ ì €ë©”ì‹œì§€ ì‚½ì…\n",
    "chathistory.add_user_message('hi')\n",
    "#add_ai_message()ë©”ì„œë“œë¥¼ ì´ìš©í•œ ìœ ì €ë©”ì‹œì§€ ì‚½ì…\n",
    "chathistory.add_user_message(\"what's up?\")\n",
    "\n",
    "chathistory.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ìƒì„±í•œ chatmessagehistoryë¥¼ chainì˜ Messageplaceholderì— ë„£ì–´ ëŒ€í™”ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"- Hi\\n- What's up?\\n\""
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chathistory.add_user_message(\n",
    "    \"Summarize the conversation in bullet points.\"\n",
    ")\n",
    "\n",
    "response = chain.invoke({\"messages\": chathistory.messages})\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ìœ„ì—ì„œ ë§Œë“  ì±—ë´‡ì„ ì´ìš©í•´ RAGë¥¼ ì ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì„œëŠ” webbaseloaderë¥¼ ì´ìš©í•´ ì¸í„°ë„·ì— ìˆëŠ” ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¤ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\n\\n\\n\\n\\nGet started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmithâ€šÃ„Ã£PythonTypeScriptpip install -U langsmithyarn add langchain langsmith2. Create an API keyâ€šÃ„Ã£To create an API key head to the Settings page. Then click Create API Key.3. Set up your environmentâ€šÃ„Ã£Shellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it\\'s not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>4. Log your first traceâ€šÃ„Ã£We provide multiple ways to log traces to LangSmith. Below, we\\'ll highlight\\nhow to use traceable. See more on the Annotate code for tracing page.PythonTypeScriptimport openaifrom langsmith.wrappers import wrap_openaifrom langsmith import traceable# Auto-trace LLM calls in-contextclient = wrap_openai(openai.Client())@traceable # Auto-trace this functiondef pipeline(user_input: str):    result = client.chat.completions.create(        messages=[{\"role\": \"user\", \"content\": user_input}],        model=\"gpt-3.5-turbo\"    )    return result.choices[0].message.contentpipeline(\"Hello, world!\")# Out:  Hello there! How can I assist you today?import { OpenAI } from \"openai\";import { traceable } from \"langsmith/traceable\";import { wrapOpenAI } from \"langsmith/wrappers\";// Auto-trace LLM calls in-contextconst client = wrapOpenAI(new OpenAI());// Auto-trace this functionconst pipeline = traceable(async (user_input) => {    const result = await client.chat.completions.create({        messages: [{ role: \"user\", content: user_input }],        model: \"gpt-3.5-turbo\",    });    return result.choices[0].message.content;});await pipeline(\"Hello, world!\")// Out: Hello there! How can I assist you today?View a sample output trace.Learn more about tracing in the how-to guides.5. Run your first evaluationâ€šÃ„Ã£Evaluation requires a system to test, data to serve as test cases, and optionally evaluators to grade the results. Here we use a built-in accuracy evaluator.PythonTypeScriptfrom langsmith import Clientfrom langsmith.evaluation import evaluateclient = Client()# Define dataset: these are your test casesdataset_name = \"Sample Dataset\"dataset = client.create_dataset(dataset_name, description=\"A sample dataset in LangSmith.\")client.create_examples(    inputs=[        {\"postfix\": \"to LangSmith\"},        {\"postfix\": \"to Evaluations in LangSmith\"},    ],    outputs=[        {\"output\": \"Welcome to LangSmith\"},        {\"output\": \"Welcome to Evaluations in LangSmith\"},    ],    dataset_id=dataset.id,)# Define your evaluatordef exact_match(run, example):    return {\"score\": run.outputs[\"output\"] == example.outputs[\"output\"]}experiment_results = evaluate(    lambda input: \"Welcome \" + input[\\'postfix\\'], # Your AI system goes here    data=dataset_name, # The data to predict and grade over    evaluators=[exact_match], # The evaluators to score the results    experiment_prefix=\"sample-experiment\", # The name of the experiment    metadata={      \"version\": \"1.0.0\",      \"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },    { postfix: \"to Evaluations in LangSmith\" },  ],  outputs: [    { output: \"Welcome to LangSmith\" },    { output: \"Welcome to Evaluations in LangSmith\" },  ],  datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async (  run: Run,  example: Example): Promise<EvaluationResult> => {  return {    key: \"exact_match\",    score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators: [exactMatch],    metadata: {      version: \"1.0.0\",      revision_id: \"beta\",    },  });Learn more about evaluation in the how-to guides.Was this page helpful?NextTutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright Â¬Â© 2024 LangChain, Inc.\\n\\n\\n\\n', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en'})]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ê°€ì ¸ì˜¨ ë°ì´í„°ëŠ” ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ë§¤ìš° ë§ì€ ì–‘ì˜ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitter\n",
    "ë§ì€ ì–‘ì˜ ë¬¸ì„œë¥¼ í•œë²ˆì— contextë¡œ ì œê³µí•˜ëŠ” ê²ƒì€ ë§ì€ ìì›ì„ ìš”êµ¬í•˜ê±°ë‚˜ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¬ê·€ ë¬¸ì ë¶„í• ê¸°ë¥¼ ì´ìš©í•´ ë¬¸ì„œë¥¼ ë‚˜ëˆ„ì–´ì„œ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "# ë¬¸ì„œí•˜ë‚˜ì˜ ì‚¬ì´ì¦ˆëŠ” 500ì´ë©°, ê²¹ì¹˜ëŠ” ë¶€ë¶„ì€ ì—†ê²Œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chroma DBë¥¼ ì´ìš©, vector storeë¥¼ ë§Œë“­ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever ìƒì„±\n",
    "- ê´€ë ¨ìˆëŠ” ë¬¸ì„œëŠ” 4ê°œë¥¼ ê°€ì ¸ì˜¤ë„ë¡ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}),\n",
       " Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}),\n",
       " Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}),\n",
       " Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'})]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(k=4)\n",
    "\n",
    "docs = retriever.invoke(\"how can langsmith help with testing?\")\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local LLMì„ í†µí•´ ë§Œë“  Chatbotì— promptë¥¼ ì—®ì–´ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "question_answering_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user's questions based on the below context:\\n\\n{context} and must answer in Korean\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(chat, question_answering_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chathistoryì™€ Retrieverë¥¼ contextë¡œ ê°–ëŠ” chainì„ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': None,\n",
       " 'bound': RunnableBinding(bound=RunnableAssign(mapper={\n",
       "   context: RunnableLambda(format_docs)\n",
       " }), config={'run_name': 'format_inputs'})\n",
       " | ChatPromptTemplate(input_variables=['context', 'messages'], input_types={'messages': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template=\"Answer the user's questions based on the below context:\\n\\n{context} and must answer in Korean\")), MessagesPlaceholder(variable_name='messages')])\n",
       " | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x32645a8d0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x3257d1710>, model_name='cognitivecomputations/dolphin-2.9-llama3-8b-gguf', temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='http://localhost:1234/v1', openai_proxy='')\n",
       " | StrOutputParser(),\n",
       " 'kwargs': {},\n",
       " 'config': {'run_name': 'stuff_documents_chain'},\n",
       " 'config_factories': [],\n",
       " 'custom_input_type': None,\n",
       " 'custom_output_type': None}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_chain.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmithëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë„êµ¬ë¡œ, ê°œë°œìë“¤ì´ ì½”ë“œë¥¼ ì‘ì„±í•˜ê³  ì´ë¥¼ ìë™ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ì…ë ¥ ë°ì´í„°ì™€ ì¶œë ¥ ë°ì´í„°ë¥¼ ë¹„êµí•˜ëŠ” ê¸°ëŠ¥ì„ í¬í•¨í•˜ì—¬, ì½”ë“œê°€ ê¸°ëŒ€ë¥¼ ë§Œì¡±ì‹œí‚¤ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë°ëª¨ë¥¼ ì‰½ê²Œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "chathistory = ChatMessageHistory()\n",
    "\n",
    "chathistory.add_user_message(\"how can langsmith help with testing?\")\n",
    "\n",
    "document_chain.invoke(\n",
    "    {\n",
    "        \"messages\": chathistory.messages,\n",
    "        \"context\": docs,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ê²€ìƒ‰ ì²´ì¸ ìƒì„±\n",
    "- ë‹¤ìŒìœ¼ë¡œ, ê²€ìƒ‰ê¸°ë¥¼ ì²´ì¸ì— í†µí•©í•©ì‹œë‹¤. \n",
    "- ê²€ìƒ‰ê¸°ëŠ” ì‚¬ìš©ìê°€ ì „ë‹¬í•œ ë§ˆì§€ë§‰ ë©”ì‹œì§€ì™€ ê´€ë ¨ëœ ì •ë³´ë¥¼ ê²€ìƒ‰í•´ì•¼ í•˜ë¯€ë¡œ, ì´ë¥¼ ì¶”ì¶œí•˜ì—¬ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ê³  ê´€ë ¨ ë¬¸ì„œë¥¼ ê°€ì ¸ì™€ í˜„ì¬ ì²´ì¸ì˜ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤. ì´ ì»¨í…ìŠ¤íŠ¸ì™€ ì´ì „ ë©”ì‹œì§€ë“¤ì„ ë¬¸ì„œ ì²´ì¸ì— ì „ë‹¬í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "- ë˜í•œ, RunnablePassthrough.assign() ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ê° í˜¸ì¶œ ì‹œ ì¤‘ê°„ ë‹¨ê³„ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì´ ë³´ì…ë‹ˆë‹¤:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ ë‚´ìš©ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜\n",
    "def parse_retriever_input(params: Dict):\n",
    "    return params[\"messages\"][-1].content\n",
    "\n",
    "# ê²€ìƒ‰ ì²´ì¸ì„ êµ¬ì„±í•˜ê³ , ë¬¸ì„œ ì²´ì¸ì— ì—°ê²°\n",
    "retrieval_chain = RunnablePassthrough.assign(\n",
    "    context=parse_retriever_input | retriever,  # ë§ˆì§€ë§‰ ë©”ì‹œì§€ë¥¼ ê²€ìƒ‰ê¸°ì— ì „ë‹¬\n",
    ").assign(\n",
    "    answer=document_chain,  # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¬¸ì„œ ì²´ì¸ì— ì „ë‹¬í•˜ì—¬ ë‹µë³€ ìƒì„±\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='how can langsmith help with testing?'),\n",
       "  AIMessage(content='LangSmithëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë„êµ¬ë¡œ, ê°œë°œìë“¤ì´ ì½”ë“œë¥¼ ì‘ì„±í•˜ê³  ì´ë¥¼ ìë™ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ì…ë ¥ ë°ì´í„°ì™€ ì¶œë ¥ ë°ì´í„°ë¥¼ ë¹„êµí•˜ëŠ” ê¸°ëŠ¥ì„ í¬í•¨í•˜ì—¬, ì½”ë“œê°€ ê¸°ëŒ€ë¥¼ ë§Œì¡±ì‹œí‚¤ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë°ëª¨ë¥¼ ì‰½ê²Œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'),\n",
       "  HumanMessage(content='ì¢€ë” ìì„¸íˆ ë§í•´ë´')],\n",
       " 'context': [Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}),\n",
       "  Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}),\n",
       "  Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}),\n",
       "  Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'})],\n",
       " 'answer': 'LangSmithëŠ” ê°œë°œìë“¤ì´ ì½”ë“œë¥¼ ì‘ì„±í•˜ê³  ì´ë¥¼ ìë™ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ì…ë ¥ ë°ì´í„°ì™€ ì¶œë ¥ ë°ì´í„°ë¥¼ ë¹„êµí•˜ëŠ” ê¸°ëŠ¥ì„ í¬í•¨í•˜ì—¬, ì½”ë“œê°€ ê¸°ëŒ€ë¥¼ ë§Œì¡±ì‹œí‚¤ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë°ëª¨ë¥¼ ì‰½ê²Œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê¸°ëŠ¥ì€ ê°œë°œìë“¤ì´ ì½”ë“œë¥¼ í…ŒìŠ¤íŠ¸í•˜ê³  ë²„ê·¸ë¥¼ ì°¾ëŠ”ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.\\n'}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aiì˜ ë‹µë³€ì„ ì¶”ê°€í•˜ê¸° ìœ„í•´ ë¨¼ì € res\n",
    "response = retrieval_chain.invoke(\n",
    "    {'messages' : chathistory.messages}\n",
    "    )\n",
    "\n",
    "chathistory.add_ai_message(response['answer'])\n",
    "chathistory.add_user_message(\"ì¢€ë” ìì„¸íˆ ë§í•´ë´\")\n",
    "\n",
    "response = retrieval_chain.invoke(\n",
    "    {'messages' : chathistory.messages}\n",
    "    )\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context :  [Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}), Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}), Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}), Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'})] \n",
      "\n",
      "answer :  LangSmithëŠ” ê°œë°œìë“¤ì´ ì½”ë“œë¥¼ ì‘ì„±í•˜ê³  ì´ë¥¼ ìë™ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ì…ë ¥ ë°ì´í„°ì™€ ì¶œë ¥ ë°ì´í„°ë¥¼ ë¹„êµí•˜ëŠ” ê¸°ëŠ¥ì„ í¬í•¨í•˜ì—¬, ì½”ë“œê°€ ê¸°ëŒ€ë¥¼ ë§Œì¡±ì‹œí‚¤ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë°ëª¨ë¥¼ ì‰½ê²Œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê¸°ëŠ¥ì€ ê°œë°œìë“¤ì´ ì½”ë“œë¥¼ í…ŒìŠ¤íŠ¸í•˜ê³  ë²„ê·¸ë¥¼ ì°¾ëŠ”ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"context : \",response['context'],'\\n')\n",
    "print(\"answer : \",response['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ìœ„ ê³¼ì •ì„ í†µí•´ chatbotì— ë©”ëª¨ë¦¬ì™€ contextë¥¼ ì¶”ê°€í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ì•˜ìŠµë‹ˆë‹¤.\n",
    "- ì•„ë˜ ì½”ë“œì²˜ëŸ¼ assignì„ í•œ ë²ˆ ë” í˜¸ì¶œí•˜ì§€ ì•Šê³  |ë¥¼ ì´ìš©í•˜ì—¬ document_chainì„ ë„£ì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmithëŠ” ê°œë°œìë“¤ì´ ì½”ë“œë¥¼ ì‘ì„±í•˜ê³  ì´ë¥¼ ìë™ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ì…ë ¥ ë°ì´í„°ì™€ ì¶œë ¥ ë°ì´í„°ë¥¼ ë¹„êµí•˜ëŠ” ê¸°ëŠ¥ì„ í¬í•¨í•˜ì—¬, ì½”ë“œê°€ ê¸°ëŒ€ë¥¼ ë§Œì¡±ì‹œí‚¤ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë°ëª¨ë¥¼ ì‰½ê²Œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê¸°ëŠ¥ì€ ê°œë°œìë“¤ì´ ì½”ë“œë¥¼ í…ŒìŠ¤íŠ¸í•˜ê³  ë²„ê·¸ë¥¼ ì°¾ëŠ”ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.\\n'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain_with_only_answer = (\n",
    "    RunnablePassthrough.assign(\n",
    "        context=parse_retriever_input |\n",
    "                retriever,\n",
    "    )\n",
    "    | document_chain\n",
    ")\n",
    "\n",
    "retrieval_chain_with_only_answer.invoke(\n",
    "    {\n",
    "        \"messages\": chathistory.messages,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query transformation\n",
    "- ì—¬ê¸°ì„œ ë‹¤ë£° ë§ˆì§€ë§‰ ìµœì í™”ì— ëŒ€í•´ ì„¤ëª…í•˜ê² ìŠµë‹ˆë‹¤ \n",
    "- ìœ„ ì˜ˆì œì—ì„œ, 'ì¢€ ë” ìì„¸íˆ ë§í•´ì¤˜!'ë¼ëŠ” í›„ì† ì§ˆë¬¸ì„ í–ˆì„ ë•Œ, ê²€ìƒ‰ëœ ë¬¸ì„œì— í…ŒìŠ¤íŠ¸ì— ëŒ€í•œ ì •ë³´ê°€ ì§ì ‘ì ìœ¼ë¡œ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- ì´ëŠ” 'ì¢€ ë” ìì„¸íˆ ë§í•´ì¤˜!'ë¼ëŠ” ì§ˆë¬¸ì„ ê²€ìƒ‰ê¸°ì— ê·¸ëŒ€ë¡œ ì¿¼ë¦¬ë¡œ ì „ë‹¬í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ê²€ìƒ‰ ì²´ì¸ì˜ ì¶œë ¥ì€ ì—¬ì „íˆ ê´œì°®ìŠµë‹ˆë‹¤.\n",
    "- ì™œëƒí•˜ë©´ ë¬¸ì„œ ì²´ì¸ ê²€ìƒ‰ ì²´ì¸ì´ ì±„íŒ… ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ì§€ë§Œ, ë” í’ë¶€í•˜ê³  ìœ ìµí•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}),\n",
       " Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}),\n",
       " Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}),\n",
       " Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'})]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}),\n",
       " Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}),\n",
       " Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}),\n",
       " Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'})]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"ì¢€ ë” ìì„¸íˆ ë§í•´ì¤˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì´ëŸ¬í•œ ì¼ë°˜ì ì¸ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì…ë ¥ì—ì„œ ì°¸ì¡°ë¥¼ ì œê±°í•˜ëŠ” ì¿¼ë¦¬ ë³€í™˜ ë‹¨ê³„ë¥¼ ì¶”ê°€í•©ì‹œë‹¤. ë‹¤ìŒê³¼ ê°™ì´ ê¸°ì¡´ ê²€ìƒ‰ê¸°ë¥¼ ê°ì‹¸ê² ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "# We need a prompt that we can pass into an LLM to generate a transformed search query\n",
    "\n",
    "query_transform_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation. Only respond with the query, nothing else.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "query_transforming_retriever_chain = RunnableBranch(\n",
    "    (\n",
    "        lambda x: len(x.get(\"messages\", [])) == 1,\n",
    "        # If only one message, then we just pass that message's content to retriever\n",
    "        (lambda x: x[\"messages\"][-1].content) | retriever,\n",
    "    ),\n",
    "    # If messages, then we pass inputs to LLM chain to transform the query, then pass to retriever\n",
    "    query_transform_prompt | chat | StrOutputParser() | retriever,\n",
    ").with_config(run_name=\"chat_retriever_chain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ì´ì œ ìƒˆë¡œìš´ query_transforming_retriever_chainì„ ì‚¬ìš©í•˜ì—¬ ì´ì „ ì²´ì¸ì„ ë‹¤ì‹œ ë§Œë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤. \n",
    "- ì´ ìƒˆë¡œìš´ ì²´ì¸ì€ ì…ë ¥ìœ¼ë¡œ dictë¥¼ ë°›ì•„ì„œ ê²€ìƒ‰ê¸°ì— ì „ë‹¬í•  ë¬¸ìì—´ì„ íŒŒì‹±í•˜ë¯€ë¡œ, ìƒìœ„ ë ˆë²¨ì—ì„œ ì¶”ê°€ íŒŒì‹±ì„ í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain = create_stuff_documents_chain(chat, question_answering_prompt)\n",
    "\n",
    "conversational_retrieval_chain = RunnablePassthrough.assign(\n",
    "    context=query_transforming_retriever_chain,\n",
    ").assign(\n",
    "    answer=document_chain,\n",
    ")\n",
    "\n",
    "demo_ephemeral_chat_history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='how can langsmith help with testing?'),\n",
       "  AIMessage(content='LangSmithëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë„êµ¬ë¡œ, ê°œë°œìë“¤ì´ ì½”ë“œë¥¼ ì‘ì„±í•˜ê³  ì´ë¥¼ ìë™ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ì…ë ¥ ë°ì´í„°ì™€ ì¶œë ¥ ë°ì´í„°ë¥¼ ë¹„êµí•˜ëŠ” ê¸°ëŠ¥ì„ í¬í•¨í•˜ì—¬, ì½”ë“œê°€ ê¸°ëŒ€ë¥¼ ë§Œì¡±ì‹œí‚¤ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë°ëª¨ë¥¼ ì‰½ê²Œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')],\n",
       " 'context': [Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}),\n",
       "  Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}),\n",
       "  Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}),\n",
       "  Document(page_content='Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'})],\n",
       " 'answer': 'LangSmithëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë„êµ¬ë¡œ, ê°œë°œìë“¤ì´ ì½”ë“œë¥¼ ì‘ì„±í•˜ê³  ì´ë¥¼ ìë™ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ì…ë ¥ ë°ì´í„°ì™€ ì¶œë ¥ ë°ì´í„°ë¥¼ ë¹„êµí•˜ëŠ” ê¸°ëŠ¥ì„ í¬í•¨í•˜ì—¬, ì½”ë“œê°€ ê¸°ëŒ€ë¥¼ ë§Œì¡±ì‹œí‚¤ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë°ëª¨ë¥¼ ì‰½ê²Œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_ephemeral_chat_history.add_user_message(\"how can langsmith help with testing?\")\n",
    "\n",
    "response = conversational_retrieval_chain.invoke(\n",
    "    {\"messages\": demo_ephemeral_chat_history.messages},\n",
    ")\n",
    "\n",
    "demo_ephemeral_chat_history.add_ai_message(response[\"answer\"])\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='how can langsmith help with testing?'),\n",
       "  AIMessage(content='LangSmithëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë„êµ¬ë¡œ, ê°œë°œìë“¤ì´ ì½”ë“œë¥¼ ì‘ì„±í•˜ê³  ì´ë¥¼ ìë™ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ì…ë ¥ ë°ì´í„°ì™€ ì¶œë ¥ ë°ì´í„°ë¥¼ ë¹„êµí•˜ëŠ” ê¸°ëŠ¥ì„ í¬í•¨í•˜ì—¬, ì½”ë“œê°€ ê¸°ëŒ€ë¥¼ ë§Œì¡±ì‹œí‚¤ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë°ëª¨ë¥¼ ì‰½ê²Œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'),\n",
       "  HumanMessage(content='tell me more about that!')],\n",
       " 'context': [Document(page_content='Skip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmithâ€šÃ„Ã£PythonTypeScriptpip install -U langsmithyarn add langchain', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}),\n",
       "  Document(page_content='Skip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmithâ€šÃ„Ã£PythonTypeScriptpip install -U langsmithyarn add langchain', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}),\n",
       "  Document(page_content='Skip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmithâ€šÃ„Ã£PythonTypeScriptpip install -U langsmithyarn add langchain', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'}),\n",
       "  Document(page_content='Skip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmithâ€šÃ„Ã£PythonTypeScriptpip install -U langsmithyarn add langchain', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffÃ¼Â¶ÃºÃ”âˆÃ¨\\uf8ffÃ¼Ãµâ€ Ã”âˆÃ¨ LangSmith'})],\n",
       " 'answer': 'LangSmithëŠ” ê°œë°œìë“¤ì´ LLM(Logic-Driven Machine) ì•±ì„ ë¹ ë¥´ê³  ì‹ ë¢°ì„±ìˆê²Œ ê°œë°œí•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤. LangSmithëŠ” ì•±ì˜ ì„±ëŠ¥ê³¼ ì•ˆì •ì„±ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  í‰ê°€í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, LangChainì´ í•„ìš”í•˜ì§€ ì•Šìœ¼ë©°, LangSmithë§Œìœ¼ë¡œë„ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n'}"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_ephemeral_chat_history.add_user_message(\"tell me more about that!\")\n",
    "\n",
    "conversational_retrieval_chain.invoke(\n",
    "    {\"messages\": demo_ephemeral_chat_history.messages}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Teddy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
