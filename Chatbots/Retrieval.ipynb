{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "- 검색은 챗봇이 훈련 데이터 외부의 데이터로 응답을 보강하는 일반적인 기술입니다. \n",
    "- 이 섹션에서는 챗봇의 맥락에서 검색을 구현하는 방법을 다룰 것입니다. \n",
    "- 하지만 검색은 매우 미묘하고 깊은 주제임을 알아두는 것이 좋습니다 \n",
    "- 문서의 다른 부분을 탐색하여 더 깊이 있는 내용을 살펴보도록 권장합니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv('../dot.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet langchain langchain-openai langchain-chroma beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 예제는 langsmith 공식문서의 내용을 바탕으로 답변하는 검색기 예제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith'}),\n",
       " Document(page_content='Skip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmith‚ÄãPythonTypeScriptpip install -U langsmithyarn add langchain', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith'}),\n",
       " Document(page_content='\"1.0.0\",      revision_id: \"beta\",    },  });Learn more about evaluation in the how-to guides.Was this page helpful?You can leave detailed feedback on GitHub.NextTutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2024 LangChain, Inc.', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith'}),\n",
       " Document(page_content=\"langsmith2. Create an API key‚ÄãTo create an API key head to the Settings page. Then click Create API Key.3. Set up your environment‚ÄãShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it's not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>4. Log your first trace‚ÄãWe provide multiple ways to log traces to LangSmith. Below, we'll highlight\", metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith'})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "data = loader.load()\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# k is the number of chunks to retrieve\n",
    "retriever = vectorstore.as_retriever(k=4)\n",
    "\n",
    "docs = retriever.invoke(\"Can LangSmith help test my LLM applications?\")\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "SYSTEM_TEMPLATE = \"\"\"\n",
    "Answer the user's questions based on the below context. \n",
    "If the context doesn't contain any relevant information to the question, don't make something up and just say \"I don't know\" and please answer in Korean:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\"\"\"\n",
    "\n",
    "question_answering_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            SYSTEM_TEMPLATE,\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(chat, question_answering_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 prompt를 확인하면 document_chain에 들어가는 변수들 간의 관계를 알 수 있습니다.\n",
    "\n",
    "특히 중요한 변수는 context와 messages입니다. \n",
    "context는 위에서 정의한 vectorstore에서 가져온 문서들을 말하며, \n",
    "messages는 사용자의 질문에 대한 답변을 만들어내는 변수입니다. \n",
    "즉, 사용자가 질문한 내용을 바탕으로 문서를 검색하고, 그 결과를 바탕으로 답변을 만들어내는 과정을 거쳐야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'messages'], input_types={'messages': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template='\\nAnswer the user\\'s questions based on the below context. \\nIf the context doesn\\'t contain any relevant information to the question, don\\'t make something up and just say \"I don\\'t know\" and please answer in Korean:\\n\\n<context>\\n{context}\\n</context>\\n')), MessagesPlaceholder(variable_name='messages')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answering_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith는 LLM 애플리케이션을 테스트하는 데 도움을 줄 수 있습니다.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "document_chain.invoke(\n",
    "    {\n",
    "        \"context\": docs,\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Can LangSmith help test my LLM applications?\")\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 langsmith docs를 context로 주지 않았을 때의 답변입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'제가 알기로는 LangSmith는 LLM 애플리케이션을 테스트하는 데 도움을 줄 수 있습니다. 그러나 구체적인 세부 정보는 알 수 없습니다. 도움이 필요하시면 LangSmith에게 직접 문의해보시는 것이 좋을 것 같습니다.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_chain.invoke(\n",
    "    {\n",
    "        \"context\": [],\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Can LangSmith help test my LLM applications?\")\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 위에서 생성한 doc chain과 검색기를 연결해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Dict\n",
    "\n",
    "# from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# # 'params' 사전에서 마지막 메시지의 내용을 추출하는 함수\n",
    "# def parse_retriever_input(params: Dict):\n",
    "#     return params[\"messages\"][-1].content\n",
    "\n",
    "# # 검색 체인을 설정합니다. 이 체인은 입력된 메시지를 처리하여 적절한 문서를 검색하고,\n",
    "# # 그 결과를 document_chain에 전달하여 최종 답변을 생성합니다.\n",
    "# ''' RunnablePassthrough.assign은 체인의 다음 단계로 데이터를 전달하는 데 사용됩니다.\n",
    "#  document_chain의 앞단에 parse_retriever_input과 retriever를 연결하여 \n",
    "#  마지막 메시지를 검색기에 전달하고, 그 결과를 document_chain에 전달하여 답변을 생성합니다.'''\n",
    "\n",
    "# retrieval_chain = RunnablePassthrough.assign(\n",
    "#     context=parse_retriever_input | retriever,  # 마지막 메시지를 검색기에 전달\n",
    "# ).assign(\n",
    "#     answer=document_chain,  # 검색 결과를 document_chain에 전달하여 답변 생성\n",
    "# )\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def parse_retriever_input(params: Dict):\n",
    "    return params[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "retrieval_chain = RunnablePassthrough.assign(\n",
    "    context=parse_retriever_input | retriever,\n",
    ").assign(\n",
    "    answer=document_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': None,\n",
       " 'first': RunnableAssign(mapper={\n",
       "   context: RunnableLambda(parse_retriever_input)\n",
       "            | VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x115dd7290>)\n",
       " }),\n",
       " 'middle': [],\n",
       " 'last': RunnableAssign(mapper={\n",
       "   answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "             context: RunnableLambda(format_docs)\n",
       "           }), config={'run_name': 'format_inputs'})\n",
       "           | ChatPromptTemplate(input_variables=['context', 'messages'], input_types={'messages': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template='\\nAnswer the user\\'s questions based on the below context in Korean. \\nIf the context doesn\\'t contain any relevant information to the question, don\\'t make something up and just say \"I don\\'t know\":\\n\\n<context>\\n{context}\\n</context>\\n')), MessagesPlaceholder(variable_name='messages')])\n",
       "           | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x114dba510>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x114dc2350>, model_name='gpt-3.5-turbo-1106', temperature=0.2, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "           | StrOutputParser(), config={'run_name': 'stuff_documents_chain'})\n",
       " })}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Can LangSmith help test my LLM applications?')],\n",
       " 'context': [Document(page_content='Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith'}),\n",
       "  Document(page_content='Skip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmith‚ÄãPythonTypeScriptpip install -U langsmithyarn add langchain', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith'}),\n",
       "  Document(page_content='\"1.0.0\",      revision_id: \"beta\",    },  });Learn more about evaluation in the how-to guides.Was this page helpful?You can leave detailed feedback on GitHub.NextTutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2024 LangChain, Inc.', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith'}),\n",
       "  Document(page_content=\"langsmith2. Create an API key‚ÄãTo create an API key head to the Settings page. Then click Create API Key.3. Set up your environment‚ÄãShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it's not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>4. Log your first trace‚ÄãWe provide multiple ways to log traces to LangSmith. Below, we'll highlight\", metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith'})],\n",
       " 'answer': 'Yes, LangSmith is a platform for building production-grade LLM applications and allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. It can help you test your LLM applications.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Can LangSmith help test my LLM applications?\")\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 쿼리 변환\n",
    "- 우리의 검색 체인은 LangSmith에 대한 질문에 답할 수 있지만, 문제는 챗봇이 사용자와 대화식으로 상호작용하기 때문에 후속 질문을 처리해야 한다는 점입니다. \n",
    "- 현재 형태의 체인은 이 문제를 해결하기 어렵습니다. \n",
    "- 예를 들어, 원래 질문에 대한 후속 질문으로 \"더 알려주세요!\"와 같은 질문을 고려해보세요. 검색기에 해당 쿼리를 직접 전달하면 LLM 애플리케이션 테스트와 관련 없는 문서가 반환됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith'}),\n",
       " Document(page_content='result.choices[0].message.contentpipeline(\"Hello, world!\")# Out:  Hello there! How can I assist you today?import { OpenAI } from \"openai\";import { traceable } from \"langsmith/traceable\";import { wrapOpenAI } from \"langsmith/wrappers\";// Auto-trace LLM calls in-contextconst client = wrapOpenAI(new OpenAI());// Auto-trace this functionconst pipeline = traceable(async (user_input) => {    const result = await client.chat.completions.create({        messages: [{ role: \"user\", content: user_input', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith'}),\n",
       " Document(page_content='}],        model: \"gpt-3.5-turbo\",    });    return result.choices[0].message.content;});await pipeline(\"Hello, world!\")// Out: Hello there! How can I assist you today?View a sample output trace.Learn more about tracing in the how-to guides.5. Run your first evaluation‚ÄãEvaluation requires a system to test, data to serve as test cases, and optionally evaluators to grade the results. Here we use a built-in accuracy evaluator.PythonTypeScriptfrom langsmith import Clientfrom langsmith.evaluation', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith'}),\n",
       " Document(page_content='\"1.0.0\",      revision_id: \"beta\",    },  });Learn more about evaluation in the how-to guides.Was this page helpful?You can leave detailed feedback on GitHub.NextTutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2024 LangChain, Inc.', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith'})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"Tell me more!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"LangSmith LLM application testing and evaluation\"', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 145, 'total_tokens': 155}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_482d920018', 'finish_reason': 'stop', 'logprobs': None}, id='run-d6b39a1c-0e9e-404c-98c5-67472b06f864-0', usage_metadata={'input_tokens': 145, 'output_tokens': 10, 'total_tokens': 155})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "query_transform_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation. Only respond with the query, nothing else.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "#위 query_transform_prompt는 message 내의 내서를 바탕으로 쿼리를 만들어내는 체인입니다. \n",
    "\n",
    "query_transformation_chain = query_transform_prompt | chat\n",
    "\n",
    "query_transformation_chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Can LangSmith help test my LLM applications?\"),\n",
    "            AIMessage(\n",
    "                content=\"Yes, LangSmith can help test and evaluate your LLM applications. It allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs. Additionally, LangSmith can be used to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.\"\n",
    "            ),\n",
    "            HumanMessage(content=\"Tell me more!\"),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "#query_transformation_chain은 주어진 messages를 바탕으로 \"LangSmith LLM application testing and evaluation\"라는 검색기를 위한 쿼리를 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "#Runnablebranch -> if문 형식의 분기처리를 지원 if와 else는 따로 표기하지 않는듯?'\n",
    "query_transforming_retriever_chain = RunnableBranch(\n",
    "    (\n",
    "        lambda x: len(x.get(\"messages\", [])) == 1,\n",
    "        # If only one message, then we just pass that message's content to retriever, 대화가 하나이면 llm을 사용하지 않고 그냥 검색\n",
    "        (lambda x: x[\"messages\"][-1].content) | retriever,\n",
    "    ),\n",
    "    # If messages, then we pass inputs to LLM chain to transform the query, then pass to retriever\n",
    "    query_transform_prompt | chat | StrOutputParser() | retriever,\n",
    ").with_config(run_name=\"chat_retriever_chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_TEMPLATE = \"\"\"\n",
    "Answer the user's questions based on the below context. \n",
    "If the context doesn't contain any relevant information to the question, don't make something up and just say \"I don't know\":\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\"\"\"\n",
    "\n",
    "question_answering_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            SYSTEM_TEMPLATE,\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(chat, question_answering_prompt)\n",
    "\n",
    "'''\n",
    "query_transforming_retriever_chain:\n",
    "query_transform_prompt | chat | StrOutputParser() | retriever\n",
    "그간의 메시지를 이용, 검색의 위한 쿼리를 생성하고 검색을 실행,\n",
    "이후 document chain에 해당 내용을 전달, 답변을 생성합니다.\n",
    "'''\n",
    "conversational_retrieval_chain = RunnablePassthrough.assign(\n",
    "    context=query_transforming_retriever_chain,\n",
    ").assign(\n",
    "    answer=document_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, LangSmith is a platform designed specifically for building production-grade LLM (Language Model) applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Therefore, LangSmith can indeed help test your LLM applications.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = conversational_retrieval_chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Can LangSmith help test my LLM applications?\"),\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "response['answer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Can LangSmith help test my LLM applications?'),\n",
       "  AIMessage(content='Yes, LangSmith is a platform designed specifically for building production-grade LLM (Language Model) applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Therefore, LangSmith can indeed help test your LLM applications.'),\n",
       "  HumanMessage(content='Tell me more!')],\n",
       " 'context': [Document(page_content='Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith'}),\n",
       "  Document(page_content='Skip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmith‚ÄãPythonTypeScriptpip install -U langsmithyarn add langchain', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith'}),\n",
       "  Document(page_content='\"1.0.0\",      revision_id: \"beta\",    },  });Learn more about evaluation in the how-to guides.Was this page helpful?You can leave detailed feedback on GitHub.NextTutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2024 LangChain, Inc.', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith'}),\n",
       "  Document(page_content=\"langsmith2. Create an API key‚ÄãTo create an API key head to the Settings page. Then click Create API Key.3. Set up your environment‚ÄãShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it's not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>4. Log your first trace‚ÄãWe provide multiple ways to log traces to LangSmith. Below, we'll highlight\", metadata={'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith'})],\n",
       " 'answer': 'LangSmith is a platform that enables you to closely monitor and evaluate your LLM applications, ensuring that you can ship your applications quickly and with confidence. It provides features for logging traces, creating API keys, and setting up your environment for testing and evaluation. Additionally, LangSmith offers detailed documentation and support resources to help you get started with testing and monitoring your LLM applications.'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_retrieval_chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Can LangSmith help test my LLM applications?\"),\n",
    "            AIMessage(\n",
    "                content=response['answer']\n",
    "            ),\n",
    "            HumanMessage(content=\"Tell me more!\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Teddy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
