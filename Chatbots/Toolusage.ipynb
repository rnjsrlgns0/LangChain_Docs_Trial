{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 아래는 여러 툴을 사용하며 다른 시스템과 상호작용하는 에이전트를 다룹니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet langchain-openai tavily-python\n",
    "\n",
    "# Set env var OPENAI_API_KEY or load from a .env file:\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv('../dot.env')\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "# 주어진 환경 변수가 설정되어 있지 않다면 사용자에게 입력을 요청하여 설정합니다.\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")\n",
    "_set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
    "_set_if_undefined(\"TAVILY_API_KEY\")\n",
    "\n",
    "# LangSmith 추적 기능을 활성화합니다. (선택적)\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"QA_SQL_CSV_Toolusage\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM & Tool 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "tools = [TavilySearchResults(max_results=1)]\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "# Only certain models support this\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# Adapted from https://smith.langchain.com/hub/hwchase17/openai-tools-agent\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. You may not need to use tools for every query - the user may just want to chat!\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "\n",
    "agent = create_openai_tools_agent(chat, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHi Nemo! It's great to meet you. How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"I'm Nemo!\")],\n",
       " 'output': \"Hi Nemo! It's great to meet you. How can I assist you today?\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "agent_executor.invoke({\"messages\": [HumanMessage(content=\"I'm Nemo!\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'current conservation status of the Great Barrier Reef'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.cnn.com/2022/08/04/australia/great-barrier-reef-high-coral-report-australia-climate-intl-hnk/index.html', 'content': 'CNN values your feedback\\nParts of Great Barrier Reef record highest amount of coral in 36 years\\nParts of the Great Barrier Reef have recorded their highest amount of coral cover since the Australian Institute of Marine Science (AIMS) began monitoring 36 years ago, according to a report published Thursday.\\n “In Australia, to do our share, we really need to slash our emissions reductions by 75% by 2030 and that is to hold global warming to less than 1.5 degrees which is the critical threshold for the survival of coral reef as we know it,” Muddle told CNN.\\n Many public figures, including “Aquaman” actor Jason Momoa and ocean explorer Philippe Cousteau, have called for UNESCO to add the natural wonder to its “in danger” list in hopes that it would incentivize action to save the reef.\\n On Thursday, Australia’s lower house passed a bill to enshrine the government’s commitment to reduce Australia’s emissions by 43% by 2030 in law, though it still needs the approval of the Senate.\\n AIMS CEO Dr. Paul Hardisty said the results in the north and central regions were a sign the reef could still recover from mass bleaching and outbreaks of crown-of-thorns starfish that feed on coral.\\n'}]\u001b[0m\u001b[32;1m\u001b[1;3mThe Great Barrier Reef has recorded its highest amount of coral cover since the Australian Institute of Marine Science (AIMS) began monitoring 36 years ago. This is a positive sign, indicating that the reef could still recover from mass bleaching and outbreaks of crown-of-thorns starfish that feed on coral. However, there are concerns about the survival of coral reefs due to global warming, and there have been calls for UNESCO to add the Great Barrier Reef to its \"in danger\" list in hopes of incentivizing action to save the reef.\n",
      "\n",
      "You can read more about it [here](https://www.cnn.com/2022/08/04/australia/great-barrier-reef-high-coral-report-australia-climate-intl-hnk/index.html).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the current conservation status of the Great Barrier Reef?')],\n",
       " 'output': 'The Great Barrier Reef has recorded its highest amount of coral cover since the Australian Institute of Marine Science (AIMS) began monitoring 36 years ago. This is a positive sign, indicating that the reef could still recover from mass bleaching and outbreaks of crown-of-thorns starfish that feed on coral. However, there are concerns about the survival of coral reefs due to global warming, and there have been calls for UNESCO to add the Great Barrier Reef to its \"in danger\" list in hopes of incentivizing action to save the reef.\\n\\nYou can read more about it [here](https://www.cnn.com/2022/08/04/australia/great-barrier-reef-high-coral-report-australia-climate-intl-hnk/index.html).'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "agent_executor.invoke({\"messages\": [\n",
    "    HumanMessage(\n",
    "    content=\"What is the current conservation status of the Great Barrier Reef?\")\n",
    "    ]\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# massages에 직접 그간 대화를 넣을 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Nemo! How can I assist you today, Nemo?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"I'm Nemo!\"),\n",
       "  AIMessage(content='Hello Nemo! How can I assist you today?'),\n",
       "  HumanMessage(content='What is my name?')],\n",
       " 'output': 'Your name is Nemo! How can I assist you today, Nemo?'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"I'm Nemo!\"),\n",
    "            AIMessage(content=\"Hello Nemo! How can I assist you today?\"),\n",
    "            HumanMessage(content=\"What is my name?\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 선호하는 경우, 에이전트 실행기를 RunnableWithMessageHistory 클래스에 래핑하여 내부적으로 히스토리 메시지를 관리할 수 있습니다.\n",
    " - 먼저, 래퍼가 히스토리로 저장할 입력 값을 구문 분석할 수 있도록 프롬프트를 약간 수정해야 합니다:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://smith.langchain.com/hub/hwchase17/openai-tools-agent\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. You may not need to use tools for every query - the user may just want to chat!\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "agent = create_openai_tools_agent(chat, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant. You may not need to use tools for every query - the user may just want to chat!')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10e3886d0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10f576dd0>, model_name='gpt-3.5-turbo-1106', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query']}}}]})\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.__dict__['agent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 에이전트 실행기에 여러 출력이 있기 때문에 래퍼를 초기화할 때 output_messages_key 속성을 설정해야 합니다:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain.memory에서 ChatMessageHistory를 가져옵니다.\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "# langchain_core.runnables.history에서 RunnableWithMessageHistory를 가져옵니다.\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# 데모용 휘발성 채팅 히스토리를 초기화합니다.\n",
    "demo_ephemeral_chat_history_for_chain = ChatMessageHistory()\n",
    "\n",
    "# RunnableWithMessageHistory를 사용하여 대화형 에이전트 실행기를 설정합니다.\n",
    "conversational_agent_executor = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    # 세션 ID를 받아서 데모용 휘발성 채팅 히스토리를 반환하는 람다 함수입니다.\n",
    "    # 이 함수는 각 세션에 대해 동일한 히스토리 객체를 사용하도록 설정합니다.\n",
    "    lambda session_id: demo_ephemeral_chat_history_for_chain,\n",
    "    \n",
    "    # 입력 메시지의 키를 \"input\"으로 설정합니다.\n",
    "    input_messages_key=\"input\",\n",
    "    \n",
    "    # 출력 메시지의 키를 \"output\"으로 설정합니다.\n",
    "    output_messages_key=\"output\",\n",
    "    \n",
    "    # 히스토리 메시지의 키를 \"chat_history\"로 설정합니다.\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': None,\n",
       " 'bound': RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "   chat_history: RunnableBinding(bound=RunnableLambda(_enter_history), config={'run_name': 'load_history'})\n",
       " }), config={'run_name': 'insert_history'})\n",
       " | RunnableBinding(bound=AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "     agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "   })\n",
       "   | ChatPromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant. You may not need to use tools for every query - the user may just want to chat!')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "   | RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10e3886d0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10f576dd0>, model_name='gpt-3.5-turbo-1106', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query']}}}]})\n",
       "   | OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[TavilySearchResults(max_results=1)]), config_factories=[<function Runnable.with_listeners.<locals>.<lambda> at 0x11a6853a0>]), config={'run_name': 'RunnableWithMessageHistory'}),\n",
       " 'kwargs': {},\n",
       " 'config': {},\n",
       " 'config_factories': [],\n",
       " 'custom_input_type': None,\n",
       " 'custom_output_type': None,\n",
       " 'get_session_history': <function __main__.<lambda>(session_id)>,\n",
       " 'input_messages_key': 'input',\n",
       " 'output_messages_key': 'output',\n",
       " 'history_messages_key': 'chat_history',\n",
       " 'history_factory_config': [ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agent_executor.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 37252891-8ec6-4505-abc5-5409099d1153 not found for run b4f34f88-8c02-49f9-b468-d68564df1b9a. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHi Nemo! It's great to meet you. How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"I'm Nemo!\",\n",
       " 'chat_history': [],\n",
       " 'output': \"Hi Nemo! It's great to meet you. How can I assist you today?\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"I'm Nemo!\",\n",
    "    },\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run d04875aa-37f9-45f8-83cc-49e8ce5cd230 not found for run b4a6a921-44f4-48f4-9fcf-16b2a4f79760. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Nemo! How can I assist you today, Nemo?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is my name?',\n",
       " 'chat_history': [HumanMessage(content=\"I'm Nemo!\"),\n",
       "  AIMessage(content=\"Hi Nemo! It's great to meet you. How can I assist you today?\")],\n",
       " 'output': 'Your name is Nemo! How can I assist you today, Nemo?'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"What is my name?\",\n",
    "    },\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 64695b14-79da-44b2-9a4b-27bf075dd95a not found for run bfb80aa8-05b9-4123-b935-1b25f6737c3d. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'current conservation status of the Great Barrier Reef'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.cnn.com/2022/08/04/australia/great-barrier-reef-high-coral-report-australia-climate-intl-hnk/index.html', 'content': 'CNN values your feedback\\nParts of Great Barrier Reef record highest amount of coral in 36 years\\nParts of the Great Barrier Reef have recorded their highest amount of coral cover since the Australian Institute of Marine Science (AIMS) began monitoring 36 years ago, according to a report published Thursday.\\n “In Australia, to do our share, we really need to slash our emissions reductions by 75% by 2030 and that is to hold global warming to less than 1.5 degrees which is the critical threshold for the survival of coral reef as we know it,” Muddle told CNN.\\n Many public figures, including “Aquaman” actor Jason Momoa and ocean explorer Philippe Cousteau, have called for UNESCO to add the natural wonder to its “in danger” list in hopes that it would incentivize action to save the reef.\\n On Thursday, Australia’s lower house passed a bill to enshrine the government’s commitment to reduce Australia’s emissions by 43% by 2030 in law, though it still needs the approval of the Senate.\\n AIMS CEO Dr. Paul Hardisty said the results in the north and central regions were a sign the reef could still recover from mass bleaching and outbreaks of crown-of-thorns starfish that feed on coral.\\n'}]\u001b[0m\u001b[32;1m\u001b[1;3mThe current conservation status of the Great Barrier Reef is a topic of concern. According to a report published by the Australian Institute of Marine Science (AIMS), parts of the Great Barrier Reef have recorded their highest amount of coral cover in 36 years. This is seen as a positive sign, indicating that the reef could still recover from mass bleaching and outbreaks of crown-of-thorns starfish that feed on coral. However, there are ongoing calls from public figures to add the Great Barrier Reef to UNESCO's \"in danger\" list in hopes that it would incentivize action to save the reef.\n",
      "\n",
      "If you'd like to know more details, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the current conservation status of the Great Barrier Reef?',\n",
       " 'chat_history': [HumanMessage(content=\"I'm Nemo!\"),\n",
       "  AIMessage(content=\"Hi Nemo! It's great to meet you. How can I assist you today?\"),\n",
       "  HumanMessage(content='What is my name?'),\n",
       "  AIMessage(content='Your name is Nemo! How can I assist you today, Nemo?')],\n",
       " 'output': 'The current conservation status of the Great Barrier Reef is a topic of concern. According to a report published by the Australian Institute of Marine Science (AIMS), parts of the Great Barrier Reef have recorded their highest amount of coral cover in 36 years. This is seen as a positive sign, indicating that the reef could still recover from mass bleaching and outbreaks of crown-of-thorns starfish that feed on coral. However, there are ongoing calls from public figures to add the Great Barrier Reef to UNESCO\\'s \"in danger\" list in hopes that it would incentivize action to save the reef.\\n\\nIf you\\'d like to know more details, feel free to ask!'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"What is the current conservation status of the Great Barrier Reef?\",\n",
    "    },\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Teddy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
